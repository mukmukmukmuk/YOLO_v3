{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 10013715,
          "sourceType": "datasetVersion",
          "datasetId": 6134001
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Np8KSXIBo58p"
      ]
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Library imports\n",
        "\n"
      ],
      "metadata": {
        "id": "SOYLVPJzo58X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdbpq1G6pDTz",
        "outputId": "897075fb-1a19-4d42-9133-f9a7ae59b9d0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-26T05:25:28.888759Z",
          "iopub.execute_input": "2024-11-26T05:25:28.889474Z",
          "iopub.status.idle": "2024-11-26T05:25:28.894789Z",
          "shell.execute_reply.started": "2024-11-26T05:25:28.889432Z",
          "shell.execute_reply": "2024-11-26T05:25:28.893715Z"
        },
        "jupyter": {
          "is_executing": true
        },
        "id": "hAptwiI0o58f"
      },
      "outputs": [],
      "execution_count": 50
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture"
      ],
      "metadata": {
        "id": "-p35Tn-mo58i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blocks"
      ],
      "metadata": {
        "id": "J8cdV3Ozo58j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Conv Block 정의\n",
        "class CNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,padding=0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            # TODO : (Conv, BatchNorm, LeakyReLU) 스펙 보고 구현\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, bias=False,stride=stride,padding=padding),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "# ResidualBlock 정의\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, num_repeats=1): # residual block은 input channel 수와 output channel 수가 동일하다.\n",
        "        super().__init__()\n",
        "        res_layers=[]\n",
        "        for _ in range(num_repeats):\n",
        "            res_layers.append(nn.Sequential(\n",
        "            CNNBlock(in_channels,in_channels//2,kernel_size=1,stride=1,padding=0),\n",
        "            CNNBlock(in_channels//2,in_channels,kernel_size=3,stride=1,padding=1),\n",
        "        ))\n",
        "        self.layers = nn.ModuleList(res_layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            skip_connection = x\n",
        "            x = layer(x)\n",
        "            x+=skip_connection\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "# DarkNet53 정의\n",
        "class Darknet53(nn.Module):\n",
        "    def __init__(self,in_channels=3):\n",
        "        super().__init__()\n",
        "        # TODO : define darknet53 (위에서 정의한 Conv block과 Res block 활용)\n",
        "        self.block1 = nn.Sequential(\n",
        "            CNNBlock(in_channels, 32, kernel_size=3, stride=1, padding=1),\n",
        "            CNNBlock(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            ResidualBlock(64, num_repeats=1),\n",
        "            CNNBlock(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            ResidualBlock(128, num_repeats=2),\n",
        "            CNNBlock(128, 256, kernel_size=3, stride=2, padding=1),\n",
        "            ResidualBlock(256, num_repeats=8),\n",
        "        )\n",
        "        self.block2 = nn.Sequential(\n",
        "            CNNBlock(256, 512, kernel_size=3, stride=2, padding=1),\n",
        "            ResidualBlock(512, num_repeats=8),\n",
        "        )\n",
        "        self.block3 = nn.Sequential(\n",
        "            CNNBlock(512, 1024, kernel_size=3, stride=2, padding=1),\n",
        "            ResidualBlock(1024, num_repeats=4),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO : Darknet53에서 output으로 나오는 세가지 feature map 생산\n",
        "        high_feature_map = self.block1(x)\n",
        "        medium_feature_map = self.block2(high_feature_map)\n",
        "        low_feature_map = self.block3(medium_feature_map)\n",
        "        return high_feature_map, medium_feature_map, low_feature_map\n",
        "\n",
        "class UpSampling(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.upsample = nn.Sequential(\n",
        "            # TODO : YOLO Network Architecture에서 Upsampling에 사용\n",
        "            CNNBlock(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "            nn.Upsample(scale_factor=2)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.upsample(x)\n",
        "\n",
        "\n",
        "class YoloBlock(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels):\n",
        "        super().__init__()\n",
        "        self.route_conv = nn.Sequential(\n",
        "            # TODO : define route conv & output conv\n",
        "            CNNBlock(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "            CNNBlock(out_channels, out_channels*2, kernel_size=3, stride=1, padding=1),\n",
        "            CNNBlock(out_channels*2, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "            CNNBlock(out_channels, out_channels*2, kernel_size=3, stride=1, padding=1),\n",
        "            CNNBlock(out_channels*2, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        route = self.route_conv(x)\n",
        "        return route        #DetectionLayer로 전달\n",
        "\n",
        "\n",
        "class DetectionLayer(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        # TODO : YOLO Network에서 output 된 결과를 이용하여 prediction\n",
        "\n",
        "        self.pred=nn.Sequential(\n",
        "            CNNBlock(in_channels, in_channels*2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels*2,(num_classes+5)*3 , kernel_size=1,stride=1,padding=0)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.pred(x)\n",
        "        # TODO : output에 추가적인 처리 필요\n",
        "        output = output.view(x.size(0), 3, self.num_classes + 5, x.size(2), x.size(3))\n",
        "        output = output.permute(0, 1, 3, 4, 2)\n",
        "        return output"
      ],
      "metadata": {
        "trusted": true,
        "ExecuteTime": {
          "end_time": "2024-11-27T07:14:55.409674Z",
          "start_time": "2024-11-27T07:14:53.757148Z"
        },
        "id": "YkP9x48go58k"
      },
      "outputs": [],
      "execution_count": 51
    },
    {
      "cell_type": "markdown",
      "source": [
        "## yolov3 architecture"
      ],
      "metadata": {
        "id": "te0Mc7A1o58m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLOv3(nn.Module):\n",
        "    def __init__(self, in_channels=3,num_classes = 3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.darknet = Darknet53(in_channels=in_channels)\n",
        "\n",
        "        self.yolo_block_01 = YoloBlock(1024,512)\n",
        "        self.detectlayer_01 = DetectionLayer(512, num_classes)\n",
        "        self.upsample_01 = UpSampling(512, 256)\n",
        "\n",
        "        # input_channels : darknet53 feature map 02 채널(512) + upsampling 채널(256)\n",
        "        self.yolo_block_02 = YoloBlock(512 + 256, 256)\n",
        "        self.detectlayer_02 = DetectionLayer(256, num_classes)\n",
        "        self.upsample_02 = UpSampling(256, 128)\n",
        "\n",
        "        # input_channels : darknet53 feature map 01 채널(256) + upsampling 채널(128)\n",
        "        self.yolo_block_03 = YoloBlock(256 + 128, 128)\n",
        "        self.detectlayer_03 = DetectionLayer(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        high_feature_map, medium_feature_map, low_feature_map =self.darknet(x)\n",
        "\n",
        "        x= self.yolo_block_01(low_feature_map)\n",
        "        output_01 = self.detectlayer_01(x)\n",
        "        x = self.upsample_01(x)\n",
        "\n",
        "        x = self.yolo_block_02(torch.cat([x,medium_feature_map], dim=1))\n",
        "        output_02 = self.detectlayer_02(x)\n",
        "        x = self.upsample_02(x)\n",
        "\n",
        "        x = self.yolo_block_03(torch.cat([x, high_feature_map], dim=1))\n",
        "        output_03 = self.detectlayer_03(x)\n",
        "\n",
        "        return output_01, output_02, output_03"
      ],
      "metadata": {
        "trusted": true,
        "id": "v31-1e26o58n"
      },
      "outputs": [],
      "execution_count": 52
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model test"
      ],
      "metadata": {
        "id": "79nbbOJZp0WK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 20\n",
        "IMAGE_SIZE = 416\n",
        "\n",
        "# Creating model and testing output shapes\n",
        "model = YOLOv3(num_classes=num_classes)\n",
        "x = torch.randn((1, 3, IMAGE_SIZE, IMAGE_SIZE))\n",
        "out = model(x)\n",
        "print(out[0].shape)\n",
        "print(out[1].shape)\n",
        "print(out[2].shape)\n",
        "\n",
        "# Asserting output shapes\n",
        "assert model(x)[0].shape == (1, 3, IMAGE_SIZE // 32, IMAGE_SIZE // 32, num_classes + 5) # B, RGB, cell size, cell size, (c, x, y, w, h) + classes_prob\n",
        "assert model(x)[1].shape == (1, 3, IMAGE_SIZE // 16, IMAGE_SIZE // 16, num_classes + 5)\n",
        "assert model(x)[2].shape == (1, 3, IMAGE_SIZE // 8, IMAGE_SIZE // 8, num_classes + 5)\n",
        "print(\"Output shapes are correct!\")\n",
        "\n",
        "# torch summary\n",
        "summary(model, input_size=(2, 3, IMAGE_SIZE, IMAGE_SIZE), device=\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJdCBZjdprer",
        "outputId": "1007b764-4e97-4d71-be2b-b33a0ffa739f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 13, 13, 25])\n",
            "torch.Size([1, 3, 26, 26, 25])\n",
            "torch.Size([1, 3, 52, 52, 25])\n",
            "Output shapes are correct!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==============================================================================================================\n",
              "Layer (type:depth-idx)                                       Output Shape              Param #\n",
              "==============================================================================================================\n",
              "YOLOv3                                                       [2, 3, 13, 13, 25]        --\n",
              "├─Darknet53: 1-1                                             [2, 256, 52, 52]          --\n",
              "│    └─Sequential: 2-1                                       [2, 256, 52, 52]          --\n",
              "│    │    └─CNNBlock: 3-1                                    [2, 32, 416, 416]         928\n",
              "│    │    └─CNNBlock: 3-2                                    [2, 64, 208, 208]         18,560\n",
              "│    │    └─ResidualBlock: 3-3                               [2, 64, 208, 208]         20,672\n",
              "│    │    └─CNNBlock: 3-4                                    [2, 128, 104, 104]        73,984\n",
              "│    │    └─ResidualBlock: 3-5                               [2, 128, 104, 104]        164,608\n",
              "│    │    └─CNNBlock: 3-6                                    [2, 256, 52, 52]          295,424\n",
              "│    │    └─ResidualBlock: 3-7                               [2, 256, 52, 52]          2,627,584\n",
              "│    └─Sequential: 2-2                                       [2, 512, 26, 26]          --\n",
              "│    │    └─CNNBlock: 3-8                                    [2, 512, 26, 26]          1,180,672\n",
              "│    │    └─ResidualBlock: 3-9                               [2, 512, 26, 26]          10,498,048\n",
              "│    └─Sequential: 2-3                                       [2, 1024, 13, 13]         --\n",
              "│    │    └─CNNBlock: 3-10                                   [2, 1024, 13, 13]         4,720,640\n",
              "│    │    └─ResidualBlock: 3-11                              [2, 1024, 13, 13]         20,983,808\n",
              "├─YoloBlock: 1-2                                             [2, 512, 13, 13]          --\n",
              "│    └─Sequential: 2-4                                       [2, 512, 13, 13]          --\n",
              "│    │    └─CNNBlock: 3-12                                   [2, 512, 13, 13]          525,312\n",
              "│    │    └─CNNBlock: 3-13                                   [2, 1024, 13, 13]         4,720,640\n",
              "│    │    └─CNNBlock: 3-14                                   [2, 512, 13, 13]          525,312\n",
              "│    │    └─CNNBlock: 3-15                                   [2, 1024, 13, 13]         4,720,640\n",
              "│    │    └─CNNBlock: 3-16                                   [2, 512, 13, 13]          525,312\n",
              "├─DetectionLayer: 1-3                                        [2, 3, 13, 13, 25]        --\n",
              "│    └─Sequential: 2-5                                       [2, 75, 13, 13]           --\n",
              "│    │    └─CNNBlock: 3-17                                   [2, 1024, 13, 13]         4,720,640\n",
              "│    │    └─Conv2d: 3-18                                     [2, 75, 13, 13]           76,875\n",
              "├─UpSampling: 1-4                                            [2, 256, 26, 26]          --\n",
              "│    └─Sequential: 2-6                                       [2, 256, 26, 26]          --\n",
              "│    │    └─CNNBlock: 3-19                                   [2, 256, 13, 13]          131,584\n",
              "│    │    └─Upsample: 3-20                                   [2, 256, 26, 26]          --\n",
              "├─YoloBlock: 1-5                                             [2, 256, 26, 26]          --\n",
              "│    └─Sequential: 2-7                                       [2, 256, 26, 26]          --\n",
              "│    │    └─CNNBlock: 3-21                                   [2, 256, 26, 26]          197,120\n",
              "│    │    └─CNNBlock: 3-22                                   [2, 512, 26, 26]          1,180,672\n",
              "│    │    └─CNNBlock: 3-23                                   [2, 256, 26, 26]          131,584\n",
              "│    │    └─CNNBlock: 3-24                                   [2, 512, 26, 26]          1,180,672\n",
              "│    │    └─CNNBlock: 3-25                                   [2, 256, 26, 26]          131,584\n",
              "├─DetectionLayer: 1-6                                        [2, 3, 26, 26, 25]        --\n",
              "│    └─Sequential: 2-8                                       [2, 75, 26, 26]           --\n",
              "│    │    └─CNNBlock: 3-26                                   [2, 512, 26, 26]          1,180,672\n",
              "│    │    └─Conv2d: 3-27                                     [2, 75, 26, 26]           38,475\n",
              "├─UpSampling: 1-7                                            [2, 128, 52, 52]          --\n",
              "│    └─Sequential: 2-9                                       [2, 128, 52, 52]          --\n",
              "│    │    └─CNNBlock: 3-28                                   [2, 128, 26, 26]          33,024\n",
              "│    │    └─Upsample: 3-29                                   [2, 128, 52, 52]          --\n",
              "├─YoloBlock: 1-8                                             [2, 128, 52, 52]          --\n",
              "│    └─Sequential: 2-10                                      [2, 128, 52, 52]          --\n",
              "│    │    └─CNNBlock: 3-30                                   [2, 128, 52, 52]          49,408\n",
              "│    │    └─CNNBlock: 3-31                                   [2, 256, 52, 52]          295,424\n",
              "│    │    └─CNNBlock: 3-32                                   [2, 128, 52, 52]          33,024\n",
              "│    │    └─CNNBlock: 3-33                                   [2, 256, 52, 52]          295,424\n",
              "│    │    └─CNNBlock: 3-34                                   [2, 128, 52, 52]          33,024\n",
              "├─DetectionLayer: 1-9                                        [2, 3, 52, 52, 25]        --\n",
              "│    └─Sequential: 2-11                                      [2, 75, 52, 52]           --\n",
              "│    │    └─CNNBlock: 3-35                                   [2, 256, 52, 52]          295,424\n",
              "│    │    └─Conv2d: 3-36                                     [2, 75, 52, 52]           19,275\n",
              "==============================================================================================================\n",
              "Total params: 61,626,049\n",
              "Trainable params: 61,626,049\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 65.43\n",
              "==============================================================================================================\n",
              "Input size (MB): 4.15\n",
              "Forward/backward pass size (MB): 1229.50\n",
              "Params size (MB): 246.50\n",
              "Estimated Total Size (MB): 1480.15\n",
              "=============================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Util & Loss function\n",
        "참고 자료 : https://www.geeksforgeeks.org/yolov3-from-scratch-using-pytorch/"
      ],
      "metadata": {
        "id": "Np8KSXIBo58p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting anchors"
      ],
      "metadata": {
        "id": "st3cI3GOo58p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Anchors\n",
        "ANCHORS = [\n",
        "    [(0.28, 0.22), (0.38, 0.48), (0.9, 0.78)],\n",
        "    [(0.07, 0.15), (0.15, 0.11), (0.14, 0.29)],\n",
        "    [(0.02, 0.03), (0.04, 0.07), (0.08, 0.06)],\n",
        "]\n",
        "\n",
        "GRID_SIZE = [13, 26, 52]"
      ],
      "metadata": {
        "trusted": true,
        "id": "7rtXoptVo58q"
      },
      "outputs": [],
      "execution_count": 54
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detection utils"
      ],
      "metadata": {
        "id": "wcgYhGCGo58r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def iou(box1, box2, is_pred = True):\n",
        "\n",
        "    # TODO\n",
        "    iou_score = None\n",
        "\n",
        "    return iou_score\n",
        "\n",
        "\n",
        "\n",
        "def nms(bboxes, iou_threshold, threshold):\n",
        "    # TODO\n",
        "    bboxes_nms = None\n",
        "    return bboxes_nms\n",
        "\n",
        "\n",
        "def convert_cells_to_bboxes():\n",
        "    # TODO\n",
        "    converted_bboxes = None\n",
        "    return converted_bboxes.tolist()\n",
        "\n",
        "\n",
        "def plot_image(image, boxes):\n",
        "\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "e603RTh9o58s"
      },
      "outputs": [],
      "execution_count": 55
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model checkpoint"
      ],
      "metadata": {
        "id": "n1qCqWoRo58s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(model, optimizer, filename = \"dr_bee_checkpoint.ptr.tar\"):\n",
        "    print(\"==> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "# Function to load checkpoint\n",
        "def load_checkpoint(checkpoint_file, model, optimizer, lr, device):\n",
        "    print(\"==> Loading checkpoint\")\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "6En_Tp5co58t"
      },
      "outputs": [],
      "execution_count": 56
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function"
      ],
      "metadata": {
        "id": "1GWwaVWRo58t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class YoloLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "        self.ce = nn.CrossEntropyLoss()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, pred, target, anchors):\n",
        "\n",
        "\n",
        "        # TODO\n",
        "        box_loss = 0\n",
        "        class_loss = 0\n",
        "        object_loss = 0\n",
        "        no_object_loss = 0\n",
        "\n",
        "        return(\n",
        "            box_loss\n",
        "            + object_loss\n",
        "            + no_object_loss\n",
        "            + class_loss\n",
        "        )"
      ],
      "metadata": {
        "trusted": true,
        "id": "sME-_z6_o58t"
      },
      "outputs": [],
      "execution_count": 57
    }
  ]
}